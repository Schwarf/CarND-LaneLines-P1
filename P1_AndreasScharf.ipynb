{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview over project files\n",
    "* Documentation/writeup in FindingLaneLines.pdf\n",
    "* My local results on videos and images in folder: MyResultsVideosAndImages\n",
    "* Source code written with Eclipse-Pydev in folder (using cv2 instead of moviepy for video processing): MySource\n",
    "* Writeup pictures and WORD document in folder: MyWriteup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob, os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "My (final) pipeline consists of several steps which are \n",
    "1. Converting the image from BGR space to HSV space\n",
    "2. Applying a yellow and a white color mask \n",
    "3. Converting the HSV image to a gray colored image\n",
    "4. Applying a smoothing of the picture to reduce noise effects.\n",
    "5. Apply an edge detection algorithm, here the Canny algorithm.\n",
    "6. Defining a region of interest, where lines forming road lanes should be identified.\n",
    "7. Using the Hough transform to identify lines in the image\n",
    "8. Using a linear/quadratic fit to identify the lane lines.\n",
    "9. Draw the resulting lines in the picture\n",
    "    * Draw one line for each lane line only implemented for linear fit.\n",
    "    * Draw line segments for quadratic fit \n",
    "    \n",
    "### Problems with color spaces in moviepy and cv2\n",
    "I encounterd a problem when I used movie.py instead of cv2 (my original choice) to capture the videos. To see the difference see the different colors (red and blue) in test-videos and test-images. In both cases I work with RGB but in cv2 I get blue colors while I get red colors using moviepy. It seems that RGB and BGR a defined differently in the two libraries. As result my challenge-video and the solidYellowLeft video didn't work at beginning in jupyter-notebook and only showed one blue lane line instead of two red lane lines.\n",
    "IN my IDE (eclipse-pydev) I used cv2 and BGR2GRAY. To get the same results using moviepy and jupyter I had to adjust all my color transformations and use e.g. RGB2GRAY instead of BGR2GRAY. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Created on Sep 11, 2017\n",
    "\n",
    "@author: andre\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import glob, os\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "This class is used for the purpose to identify yellow and white structures on an image \n",
    "and perform the following transformations\n",
    "RGB -> GRAY\n",
    "RGB -> HSV\n",
    "HSV -> GRAY \n",
    "'''\n",
    "class ColorTransformations(object):\n",
    "    def ConvertBGRImageToGrayColorSpace(self,image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    def ConvertImageToHSVSpace(self, image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    def ConvertHSVImageToGrayColorSpace(self, image):\n",
    "        image1 = cv2.cvtColor(image, cv2.COLOR_HSV2RGB)\n",
    "        return self.ConvertBGRImageToGrayColorSpace(image1)\n",
    "\n",
    "    def YellowHSVMask(self,image):\n",
    "        yellowHSVLow  = np.array([ 0, 80, 200])\n",
    "        yellowHSVHigh = np.array([ 40, 255, 255])\n",
    "        return cv2.inRange(image,yellowHSVLow, yellowHSVHigh)\n",
    "        \n",
    "    def WhiteHSVMask(self,image):\n",
    "        whiteHSVLow  = np.array([  20,   0,   200])\n",
    "        whiteHSVHigh = np.array([ 255,  80, 255])\n",
    "        return cv2.inRange(image,whiteHSVLow, whiteHSVHigh)\n",
    "    \n",
    "    def ApplyWhiteAnYellowColorMasks(self, image):\n",
    "        yellowMask = self.YellowHSVMask(image)\n",
    "        whiteMask = self.WhiteHSVMask(image)\n",
    "        mask = cv2.bitwise_or(yellowMask, whiteMask)\n",
    "        filtered = cv2.bitwise_and(image, image, mask = mask)\n",
    "        return filtered\n",
    "\n",
    "'''\n",
    "This is the central class which processes all images.\n",
    "'''\n",
    "class LaneRecognition(object):\n",
    "    '''\n",
    "     Constructor \n",
    "     '''\n",
    "    def __init__(self):\n",
    "        self.Color = ColorTransformations\n",
    "\n",
    "    def ApplyCannyEdgeDetection(self, image, lowerThreshold=50, upperThreshold=150):\n",
    "        return cv2.Canny(image, lowerThreshold, upperThreshold)\n",
    "        \n",
    "    def ApplyGaussianSmoothing(self, image, kernelSize =5):\n",
    "        return cv2.GaussianBlur(image,(kernelSize, kernelSize),0)\n",
    "    \n",
    "    \n",
    "    def YTetragonBorder(self, yImageSize, yRegionRatio):\n",
    "        return yImageSize - (int (float (yImageSize) * yRegionRatio))\n",
    "    \n",
    "    '''\n",
    "    Generates a tetragon-mask based on the image size and the following two inputs \n",
    "    yRegionRatio: Gives the ratio of the considered image in y direction, which will be used to build the tetragon  \n",
    "    xQuadTopWidth: Gives the full width of the tetragon at the top. BottomWidth is full x-range of image  \n",
    "    The mask is applied bitwise to the input-image and the result is returned\n",
    "    '''\n",
    "    def DefineTetragonROIAndApplyToImage(self, image, yRegionRatio, xTetragonTopWidth = 80):\n",
    "        yImage = image.shape[0]\n",
    "        xImage = image.shape[1]\n",
    "        mask = np.zeros_like(image)\n",
    "        xTopLeft = xImage/2 - xTetragonTopWidth/2\n",
    "        xTopRight = xImage/2 + xTetragonTopWidth/2\n",
    "        xBottomLeft = 0\n",
    "        xBottomRight = xImage\n",
    "        yBottom = yImage\n",
    "        yTetragonBorder = self.YTetragonBorder(yImage, yRegionRatio)\n",
    "        tetragonEdges = np.array([[(xBottomLeft, yBottom), (xTopLeft, yTetragonBorder), (xTopRight, yTetragonBorder), (xBottomRight, yBottom)]], dtype= np.int32)\n",
    "        cv2.fillPoly(mask, tetragonEdges, 255)\n",
    "        result = cv2.bitwise_and(image,mask)\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    '''\n",
    "     Angular resolution converted in radians, input in degrees\n",
    "    '''\n",
    "    def ProbalisticHoughTransform(self, image, distanceResolution =2, angularResolution=1, numberOfPointsDefiningALine = 15, minimalLineLength = 20, maximalLineGap=20):\n",
    "        angularResolution = angularResolution*np.pi/180.0\n",
    "        identifiedLines = cv2.HoughLinesP(image, distanceResolution, angularResolution, numberOfPointsDefiningALine, np.array([]), minimalLineLength, maximalLineGap)\n",
    "        return identifiedLines\n",
    "    \n",
    "    '''\n",
    "    Draw lines into an empty image \n",
    "    '''\n",
    "    def CreateLineImage(self, lines, emptyImage):\n",
    "        for line in lines:\n",
    "            for x1,y1,x2,y2 in line:\n",
    "                '''\n",
    "                Check if length of lines is a good discriminator \n",
    "                Answer: No\n",
    "                x = x1 - x2\n",
    "                y = y1 - y2\n",
    "                res = (x**2 + y**2)**.5\n",
    "                if(res > 120):\n",
    "                    cv2.line(emptyImage,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "                elif(res > 80):\n",
    "                    cv2.line(emptyImage,(x1,y1),(x2,y2),(0,255,0),10)\n",
    "                else:\n",
    "                    cv2.line(emptyImage,(x1,y1),(x2,y2),(0,0,255),10)\n",
    "                '''\n",
    "                cv2.line(emptyImage,(x1,y1),(x2,y2),(255,0,0),10)\n",
    "        return emptyImage\n",
    "                \n",
    "    \n",
    "    '''\n",
    "    Reduce the number of lines which are not in the direction of the lanes.\n",
    "    Central angle is choosen to be 45 degree. Default gap is 15 degree \n",
    "    '''\n",
    "    def ApplyAngleFiltering(self, lines, centralAngle = 45, angleGap=15):\n",
    "        lowerAngle = math.radians(centralAngle-angleGap)\n",
    "        upperAngle = math.radians(centralAngle+angleGap) \n",
    "        filteredLines = []\n",
    "        if lines is None:\n",
    "            return filteredLines\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                slope = (y2-y1)/(x2-x1)\n",
    "                angle = abs(math.atan(slope))\n",
    "                if(angle > lowerAngle and angle < upperAngle):\n",
    "                    filteredLines.append( [[x1, y1, x2, y2]] )\n",
    "        return filteredLines\n",
    "\n",
    "    \n",
    "    '''\n",
    "    We have two lanes and consequently two categories for all lines: \n",
    "    a) Lines with negative slope represent the left lane (coordinate system of image)\n",
    "    b) Lines with positive slope represent the right lane\n",
    "    Does a linear assumption using the mean values of left/right lines work?\n",
    "    Answer: NO, not good enough. Resulting lanes are flickering/unstable and detection in video 'challenge.mp4' is bad\n",
    "    '''\n",
    "    def IdentifyLanes(self, lines, yImageLowerBorder, xImageRightBorder, yRegionRatio):\n",
    "        leftLane = [[0,0,0,0]]\n",
    "        rightLane = [[0,0,0,0]]\n",
    "        leftLaneSlope = 0\n",
    "        rightLaneSlope = 0\n",
    "        \n",
    "        leftLaneLineSlopes = [] \n",
    "        rightLaneLineSlopes = []\n",
    "        rightLaneLineIntercepts = []\n",
    "        leftLaneLineIntercepts = []\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if(abs(x2-x1) < 1.e-3):\n",
    "                    continue\n",
    "                slope = float(y2-y1)/float(x2-x1)\n",
    "                xCenter = (int )(xImageRightBorder/2)\n",
    "                if( slope < 0):\n",
    "                    leftLaneLineSlopes.append(slope)\n",
    "                    leftLaneLineIntercepts.append(y1-slope*x1)\n",
    "                    \n",
    "                elif(slope >0):\n",
    "                    rightLaneLineSlopes.append(slope)\n",
    "                    rightLaneLineIntercepts.append(y1-slope*x1)\n",
    "                    \n",
    "        # Calculate the mean values of slope and intercept for both lanes  \n",
    "        if(len(leftLaneLineSlopes) > 0):\n",
    "            leftLaneSlope = np.mean(leftLaneLineSlopes)\n",
    "            leftLaneIntercept = np.mean(leftLaneLineIntercepts)\n",
    "        if(len(rightLaneLineSlopes) > 0):\n",
    "            rightLaneSlope = np.mean(rightLaneLineSlopes)\n",
    "            rightLaneIntercept = np.mean(rightLaneLineIntercepts)\n",
    "         \n",
    "        yTetragonBorder = self.YTetragonBorder(yImageLowerBorder, yRegionRatio)\n",
    "        \n",
    "        y1Left = yImageLowerBorder\n",
    "        y1Right = y1Left\n",
    "        y2Left = (int) (yTetragonBorder)\n",
    "        y2Right = y2Left\n",
    "        \n",
    "        if(abs(leftLaneSlope) > 1.e-8 ):\n",
    "            x1Left = (int) ((yImageLowerBorder-leftLaneIntercept)/leftLaneSlope)\n",
    "            x2Left = (int) ((yTetragonBorder-leftLaneIntercept)/leftLaneSlope)\n",
    "            leftLane = [[x1Left, y1Left, x2Left, y2Left]]\n",
    "            \n",
    "        if(abs(rightLaneSlope) > 1.e-8 ):\n",
    "            x1Right = (int) ((yImageLowerBorder-rightLaneIntercept)/rightLaneSlope)\n",
    "            x2Right = (int) ((yTetragonBorder-rightLaneIntercept)/rightLaneSlope)\n",
    "            rightLane = [[x1Right, y1Right, x2Right, y2Right]]\n",
    "            \n",
    "        \n",
    "        return [leftLane, rightLane]\n",
    "    \n",
    "    '''\n",
    "    Create fit function from (x,y) value pairs and return new y values\n",
    "    '''\n",
    "    def CalculateLanePoints(self, x,y,degree):\n",
    "        try:\n",
    "            laneFit = np.polyfit(x,y,degree)\n",
    "            laneFunction = np.poly1d(laneFit)\n",
    "            return laneFunction(x).astype(int)\n",
    "        except TypeError:\n",
    "            return np.ndarray([0])\n",
    "    \n",
    "    '''\n",
    "    Using polynomial fit instead of simple linear fit\n",
    "    - Use points of all lines and assign them according to the x-Value to left and right lane\n",
    "    - Make fit and define function\n",
    "    Result is not yet satisfying, since the right lane segments are not connected.\n",
    "    '''\n",
    "    def IdentifyLinesWithPolynom(self, lines, xImageRightBorder, polynomDegree =2):\n",
    "        leftLaneLineX = []\n",
    "        leftLaneLineY = []\n",
    "        rightLaneLineX = []\n",
    "        rightLaneLineY = []\n",
    "        xCenter = (int )(xImageRightBorder/2)\n",
    "        leftLanePoints = np.column_stack(( [], [] )).reshape(-1,1,2)\n",
    "        rightLanePoints = np.column_stack(( [], [] )).reshape(-1,1,2)\n",
    "        if(lines is None):\n",
    "            return leftLanePoints, rightLanePoints\n",
    "\n",
    "        for line in lines:\n",
    "            for x1, y1, x2, y2 in line:\n",
    "                if( x1 < xCenter and x2 < xCenter):\n",
    "                    leftLaneLineX.append(x1)\n",
    "                    leftLaneLineY.append(y1)\n",
    "                    leftLaneLineX.append(x2)\n",
    "                    leftLaneLineY.append(y2)\n",
    "\n",
    "                elif( x1 > xCenter and x2 > xCenter):\n",
    "                    rightLaneLineX.append(x1)\n",
    "                    rightLaneLineY.append(y1)\n",
    "                    rightLaneLineX.append(x2)\n",
    "                    rightLaneLineY.append(y2)\n",
    "\n",
    "        \n",
    "        newLeftLaneY = self.CalculateLanePoints(leftLaneLineX, leftLaneLineY, polynomDegree)\n",
    "        newRightLaneY= self.CalculateLanePoints(rightLaneLineX, rightLaneLineY, polynomDegree)\n",
    "        if not newLeftLaneY.any():\n",
    "            leftLaneLineX = []\n",
    "        if not newRightLaneY.any():\n",
    "            rightLaneLineX = []\n",
    "        leftLanePoints = np.column_stack(( np.asarray(leftLaneLineX), newLeftLaneY )).reshape(-1,1,2)\n",
    "        rightLanePoints = np.column_stack((np.asarray(rightLaneLineX), newRightLaneY)).reshape(-1,1,2)\n",
    "        \n",
    "        return leftLanePoints, rightLanePoints \n",
    "        \n",
    "    '''\n",
    "    Create not connected Polygon with cv2 \n",
    "    '''\n",
    "    def CreatePolygonLines(self, image, leftPoints, rightPoints):\n",
    "        image1 = cv2.polylines(image,[leftPoints],False,(255,0,0),10)\n",
    "        return cv2.polylines(image1,[rightPoints],False,(255,0,0),10)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def ProcessImage(self, image, linear):\n",
    "        yRegionRatio = 0.4\n",
    "        '''\n",
    "        ColorTransformations to identify white and yellow objects\n",
    "        '''\n",
    "        color = self.Color\n",
    "        hsv = color().ConvertImageToHSVSpace(image)\n",
    "        whiteAndYellow = color().ApplyWhiteAnYellowColorMasks(hsv)\n",
    "        gray = color().ConvertHSVImageToGrayColorSpace(whiteAndYellow)\n",
    "        #gray = color().ConvertBGRImageToGrayColorSpace(image)\n",
    "        \n",
    "        '''\n",
    "        Smoothing, CannyEdge, ROI\n",
    "        '''  \n",
    "        smoothie = self.ApplyGaussianSmoothing(gray)\n",
    "        edges = self.ApplyCannyEdgeDetection(smoothie)\n",
    "        roi = self.DefineTetragonROIAndApplyToImage(edges, yRegionRatio = yRegionRatio)\n",
    "        \n",
    "        '''\n",
    "        Line identification via HoughTransform and extrapolation.\n",
    "        Two methods are possible (depending on the video): \n",
    "        - Simple linear fit with angle filtering\n",
    "        - Polynomial fit for challenge-video\n",
    "        Goal must be to use one global function or a decision maker to decide when to use which function\n",
    "        '''        \n",
    "        identifiedLines = self.ProbalisticHoughTransform(roi)\n",
    "        emptyImage = np.copy(image)*0 # Empty frame for lines\n",
    "        #lineImage = self.CreateLineImage(identifiedLines, emptyImage)\n",
    "        \n",
    "        if(linear):\n",
    "            identifiedLines = self.ApplyAngleFiltering(identifiedLines)\n",
    "            twoLanes = self.IdentifyLanes(identifiedLines, emptyImage.shape[0],\n",
    "                                          emptyImage.shape[1], yRegionRatio = yRegionRatio)\n",
    "            lineImage = self.CreateLineImage(twoLanes, emptyImage)\n",
    "        else:\n",
    "            leftPoints, rightPoints = self.IdentifyLinesWithPolynom(identifiedLines, emptyImage.shape[1], polynomDegree=2)\n",
    "            lineImage = self.CreatePolygonLines(emptyImage, leftPoints, rightPoints)\n",
    "        \n",
    "        result = cv2.addWeighted(image, 0.8, lineImage, 1, 0)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "class ImageLaneFinder(object):\n",
    "    def __init__(self, path):\n",
    "        self.Processor = LaneRecognition()\n",
    "        self.Path = path\n",
    "    \n",
    "    def LaneImages(self):\n",
    "        for file in os.listdir(self.Path):\n",
    "            if file.endswith(\".jpg\") and not file.endswith(\"_result.jpg\"):\n",
    "                image = cv2.imread(self.Path+file)\n",
    "                result = self.Processor.ProcessImage(image, True)\n",
    "                outputPath = (self.Path+file).replace(\".jpg\", \"_result.jpg\")\n",
    "                cv2.imwrite(outputPath, result)\n",
    "            \n",
    "            \n",
    " \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Images\n",
    "\n",
    "Build your pipeline to work on the images in the directory \"test_images\"  \n",
    "**You should make sure your pipeline works well on these images before you try the videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Andreas\\Programming\\Python\\UdacitySelfDrivingCar\\Term1Projects\\Project1\\CarND-LaneLines-P1\\test_images\\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = str(os.getcwd())+\"\\\\test_images\\\\\"\n",
    "\n",
    "Images = ImageLaneFinder(path)\n",
    "Images.LaneImages()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test videos\n",
    "If the test videos show blue instead of red lines, please read my comments about the color space problem at the beginning of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First video: solidWhiteRight\n",
    "My original output video can be found in the folder MyResultsVideosAndImages: solidWhiteRightMyOutput.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Andreas\\Programming\\Python\\UdacitySelfDrivingCar\\Term1Projects\\Project1\\CarND-LaneLines-P1\n",
      "[MoviePy] >>>> Building video test_videos_output/solidWhiteRight.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidWhiteRight.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▋| 221/222 [00:04<00:00, 53.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidWhiteRight.mp4 \n",
      "\n",
      "Wall time: 4.48 s\n"
     ]
    }
   ],
   "source": [
    "white_output = 'test_videos_output/solidWhiteRight.mp4'\n",
    "print(str(os.getcwd()))\n",
    "\n",
    "LR =LaneRecognition()\n",
    "clip1 = VideoFileClip('test_videos/solidWhiteRight.mp4')\n",
    "#apply LaneFinder on videoclip\n",
    "white_clip = clip1.fl_image(lambda x: LR.ProcessImage(x, True))\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidWhiteRight.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second video: solidYellowLeft\n",
    "My original output video can be found in the folder MyResultsVideosAndImages: solidYellowLeftMyOutput.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Andreas\\Programming\\Python\\UdacitySelfDrivingCar\\Term1Projects\\Project1\\CarND-LaneLines-P1\n",
      "[MoviePy] >>>> Building video test_videos_output/solidYellowLeft.mp4\n",
      "[MoviePy] Writing video test_videos_output/solidYellowLeft.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████▉| 681/682 [00:12<00:00, 52.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/solidYellowLeft.mp4 \n",
      "\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "yellow_output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "print(str(os.getcwd()))\n",
    "\n",
    "\n",
    "clip2 = VideoFileClip('test_videos/solidYellowLeft.mp4')\n",
    "#apply LaneFinder on videoclip\n",
    "yellow_clip = clip2.fl_image(lambda x: LR.ProcessImage(x, True))\n",
    "%time yellow_clip.write_videofile(yellow_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/solidYellowLeft.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(yellow_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third video: challenge\n",
    "My original output video can be found in the folder MyResultsVideosAndImages: challengeMyOutput.mp4\n",
    "Please read comments in the writeup: FindingLaneLines.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Andreas\\Programming\\Python\\UdacitySelfDrivingCar\\Term1Projects\\Project1\\CarND-LaneLines-P1\n",
      "[MoviePy] >>>> Building video test_videos_output/challenge.mp4\n",
      "[MoviePy] Writing video test_videos_output/challenge.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 251/251 [00:09<00:00, 24.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_videos_output/challenge.mp4 \n",
      "\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "c_output = 'test_videos_output/challenge.mp4'\n",
    "print(str(os.getcwd()))\n",
    "\n",
    "\n",
    "clip3 = VideoFileClip('test_videos/challenge.mp4')\n",
    "#apply LaneFinder on videoclip\n",
    "c_clip = clip3.fl_image(lambda x: LR.ProcessImage(x, False))\n",
    "%time c_clip.write_videofile(c_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"test_videos_output/challenge.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(c_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
